{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ABCDEats Company- Customer Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The Project:** - Adicionar aqui como podemos ver os 4 tipos, com que variáveis e ideias, and add this to the report and here\n",
    "**Through Academic knowledge and research,  we know that there 4 types of customer segmentation:**\n",
    "\n",
    "\n",
    "* Demographic Segmentation- who are our customers, their age, I guess that's all we get,but again, there are cases where people buy stuff for people that depend on them. SO, again, gotta think this through \n",
    "\n",
    "* Geographic Segmentation- promotions in areas?, regions that buy the most, what is different about that region, what do they pay with more in that region, regions that buy the less and why\n",
    "\n",
    "* Psychographic Segmentation- interests, they are most probably interested in food so, so sctrach that? but could still get insights somehow, just gotta think harder\n",
    "\n",
    "* Behavioral Segmentation - Spending habits, hour which they spend, when, how often, do they spend more when they have promotions, who spends less and why, do they spend less when there is no promotion\n",
    "\n",
    "`Sources`:\n",
    "* Forbes Advisor: https://www.forbes.com/advisor/business/customer-segmentation/ \n",
    "* VWO : https://vwo.com/blog/visitor-segmentation/ \n",
    "\n",
    "**OBS, esta secção é para falarmos sobre o projecto, e depois temos que apagar estas ideias**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Group Members:**\n",
    "\n",
    "* **Guilherme Goudinho**-\n",
    "* **Maria Inês Assunção**-\n",
    "* **Osmáiny Raimundo**- \n",
    "* **Vinincius Lallo**-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **METADATA**\n",
    " * **customer_id** :  Unique identifier for each customer.\n",
    "\n",
    " * **customer_region**:  Geographic region where the customer is located.\n",
    "\n",
    " * **customer_age**:  Age of the customer.\n",
    "\n",
    " * **vendor_count**:  Number of unique vendors the customer has ordered from.\n",
    "\n",
    " * **product_count**:  Total number of products the customer has ordered.\n",
    "\n",
    " * **is_chain**:  Indicates whether the customer’s order was from a chain restaurant. From the vender_count, which ones are from a chain restaurant\n",
    "\n",
    " * **first_order** :  Number of days from the start of the dataset when the customer first placed an order.\n",
    "\n",
    "\n",
    " * **last_order** Number of days from the start of the dataset when the customer most  recently placed an order.\n",
    "\n",
    "\n",
    " * **last_promo** :  The category of the promotion or discount most recently used by the\n",
    " customer.\n",
    "\n",
    " * **payment_method** :  Method most recently used by the customer to pay for their orders.\n",
    "\n",
    " * **CUI_American, CUI_Asian, CUI_Chinese, CUI_Italian, etc**. : The amount in monetary units spent by the customer from the indicated type of cuisine.\n",
    "\n",
    " * **DOW_0 to DOW_6**:   Number of orders placed on each day of the week\n",
    " (0 =Sunday, 6 =Saturday).\n",
    "\n",
    " * **HR_0 to HR_23** :  Number of orders placed during each hour of the day\n",
    " (0 =midnight, 23 = 11 PM).\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TABLE OF CONTENTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Imports](#section-1)\n",
    "    1. [Import the needed libraries ](#subsection-1.1)\n",
    "    2. [Import dataset](#subsection-1.2)\n",
    "2. [Exploratory Data Analayis](#section-2)\n",
    "    1. [Data Exploration](#subsection-2.1)\n",
    "    2. [Data Visualization](#subsection-2.2) \n",
    "    3. [Data-preprocessing - Feature Architecture & Incoherencies](#subsection-2.3)\n",
    "    4. [Outliers](#subsection-2.4)\n",
    "    5. [Missing Values(Part 1)](#subsection-2.5)\n",
    "    6. [Data Scaling](#subsection-2.6)\n",
    "    7. [Missing Values (Part 2)](#subsection-2.7)\n",
    "3. [Feature Selection](#section-3)\n",
    "    1. [Variance Threshold](#subsection-3.1)\n",
    "    2. [Spearman's Correlation](#subsection-3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraris for our analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from math import ceil\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## If you have an error here saying ydata_profiling is not available\n",
    "## Run the instructions above\n",
    "## IF you are still unable to install `ydata-profiling` through this method, \n",
    "## Comment out the line below importing ProfileReport\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# for better resolution plots\n",
    "%config InlineBackend.figure_format = 'retina' # optionally, you can change 'svg' to 'retina'\n",
    "\n",
    "# Setting seaborn style\n",
    "sns.set()\n",
    "\n",
    "# to see all the columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1. Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1.1 Importing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing our dataset into a variable \"food-df\"\n",
    "food_df=pd.read_csv(\"DM2425_ABCDEats_DATASET.csv\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1.2 Initial Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the first 6 rows of our dataset\n",
    "food_df.head(6)\n",
    "#Comments:\n",
    "#We will have to tuirn the customer id as our index column\n",
    "#The first order was the day that the purchase was done, from 0 to 90 days, if we have day 0, it is because the purchase was made the day the datset started\n",
    "#There are purchases that din´t happen? How is it possible?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.tail(5) #Checking if there are any aggregation rows  that may affect our dataset, which in this case, there aren´t any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of columns and rows of our dataset\n",
    "print(f\"\\033[1;30mOur dataset has \\033[1;35m{food_df.shape[0]}\\033[1;30m rows and \\033[1;35m{food_df.shape[1]}\\033[1;30m columns\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the information about our dataset: column, column length, and datatype, in order to identify possible wrong dataypes\n",
    "food_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['is_chain'].value_counts() #Getting the value counts to better understand this column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing from the top rows, we realized that the `Is_Chain` colum's values show that from the vender_count column, which ones are from a chain restaurant. Hence we will alter the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['first_order'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There a NaN values, which does not make sense because there needs to be an order placed, in order to be in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['HR_0'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realized that no purchase is done at HR_O. We need to explore that better, later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1.3.Checking Duplicate Values**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the duplicated rows of our dataset, and then in the customer id column, because it is going to be our index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the duplicate values\n",
    "duplicates=food_df.duplicated().sum()\n",
    "print(f\"\\033[1;30mOur dataset has \\033[1;35m{duplicates}\\033[1;30m duplicated rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the duplicated rows\n",
    "food_df.drop_duplicates(inplace=True)\n",
    "new_duplicates=food_df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking again, if we still have duplicated rows\n",
    "print(f\"\\033[1;30mOur dataset has now \\033[1;35m{new_duplicates}\\033[1;30m duplicated rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if our customer_id column has duplicates \n",
    "customer_duplicate=food_df['customer_id'].duplicated().sum()\n",
    "print(f\"\\033[1;30mOur The customer_id column has \\033[1;35m{customer_duplicate}\\033[1;30m duplicated entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that customer_id has no duplicated values, in the coherence check section, we can set it as our index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1.4.Checking the Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will check the columns that have missing values. Missing values reduce the number of data availbale to be analysed, thus, they should be propely analised and dealt with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking how many missing values we have for each column\n",
    "\n",
    "# Checking and printing columns with missing values\n",
    "for column in food_df.columns:\n",
    "    missing_values = food_df[column].isna().sum()\n",
    "    if missing_values > 0:\n",
    "        print(f\"\\033[1;35m{column} \\033[0m has \\033[1;35m{missing_values}\\033[0m missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing \"-\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looking at data, We noticed that some missing data in categorical varibales that were labeled as - we should replace them by NaN, but to do our analysis, it would be interesting too see the behaviour of those entries, since these are categorical columns, so we will replace them by \"empty\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the - by nan\n",
    "food_df.replace(\"-\", \"empty\", inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case there are other missing values in different forms, we will replace them by NaN\n",
    "food_df.replace([\"\",\"?\",\" \",\"null\", \"NK\", \"na\"], np.nan, inplace = True)\n",
    "food_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checking and printing columns with missing values afetr the replacedment\n",
    "for column in food_df.columns:\n",
    "    missing_values = food_df[column].isna().sum()\n",
    "    if missing_values > 0:\n",
    "        print(f\"\\033[1;35m{column} \\033[0m has \\033[1;35m{missing_values}\\033[0m missing values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the unique values of the columns with missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the unique values of first_order\n",
    "food_df['first_order'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the unique values of customer_region\n",
    "food_df['customer_region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the unique values of customer_age\n",
    "food_df['customer_age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the unique values of last_promo\n",
    "food_df['last_promo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the unique values of HR_0\n",
    "food_df['HR_0'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 5 columns with missing values, later on, we will have to discuss how to deal with each of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1.5.Coherence Check**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will check the columns with wrong datatypes and correct them, we will also create new columns that will help us for the statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking again our datatypes\n",
    "food_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this result, we observed the following columns with possible wrong datatypes:\n",
    "* `customer_age`\n",
    "* `first_order`\n",
    "* `HR_0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on the the following: Ages are whole numbers; first_order should be an int because it is a day; HR_0 should be int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the customer_id column as our index column. Because it has unique values that represent each row of row of our dataset.\n",
    "food_df = food_df.set_index('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_age mudar para int\n",
    "#food_df['customer_age'] = food_df['customer_age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_order mudar para int\n",
    "#food_df['first_order'] = food_df['first_order'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking again the datatypes after the changes\n",
    "food_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.head(10) # Visualizing the values in the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We weren´t able to change the datatypes yet, because of the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section was created here becasue we created new features that will be used for the Data statistics section and visualization section, later on, we will have a Feature Engineering section on the Notebook, where we will better organize the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Hours of the day columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the HR columns into midday, evening, and late_ngiht.\n",
    "#This division was done based on the visualization section, where we observed the 3 peaks of orders.\n",
    "food_df['midday_orders'] = food_df[['HR_7', 'HR_8', 'HR_9', 'HR_10', 'HR_11', 'HR_12', 'HR_13', 'HR_14']].sum(axis=1)\n",
    "food_df['evening_orders'] = food_df[['HR_15', 'HR_16', 'HR_17', 'HR_18', 'HR_19', 'HR_20', 'HR_21']].sum(axis=1)\n",
    "food_df['late_night_orders'] = food_df[['HR_22', 'HR_23', 'HR_0', 'HR_1', 'HR_2', 'HR_3', 'HR_4', 'HR_5', 'HR_6']].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Days of the Week columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregating, monday, tuesday, wednesday and thursday into a weekday column\n",
    "food_df['Weekend']= food_df['DOW_4']+food_df['DOW_5']+ food_df['DOW_6'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregating, friday, saturday, and sunday into a weekend column\n",
    "food_df['Weekday']= food_df[[f'DOW_{i}' for i in range(0,4)]].sum(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CUIsines Columns`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following division based on assumption and observations from the visual analysis, where we saw that some cuisines could be aggregated together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['Western_Cuisine'] = food_df[['CUI_American', 'CUI_Italian', 'CUI_Chicken Dishes']].sum(axis=1)\n",
    "\n",
    "food_df['Asian_Cuisine'] = food_df[['CUI_Asian', 'CUI_Chinese', 'CUI_Indian', 'CUI_Japanese', 'CUI_Thai', 'CUI_Noodle Dishes']].sum(axis=1)\n",
    "\n",
    "food_df['Desserts_Beverages'] = food_df[['CUI_Desserts', 'CUI_Beverages', 'CUI_Cafe']].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next 2 sections, data statistics and data visualization, we will deepen our analysis on these new variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2.Data Statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to analyse the statistics regarding our features, this will help understand better our variables and their possible implications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the numerical varibales\n",
    "num_food_df=food_df.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to make an aggregation to get the total number of orders per customer, each by day of the week and hour of the day. We are doing this because while analysing our dataset in excel, we observed a difference in the total of hour of the day and the total in day of the week, as seen in the image bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrp = Image.open('discrepancy.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(discrp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we try to observe this using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the total orders by the days of the week into a new column\n",
    "food_df['Total orders'] = food_df[['DOW_0', 'DOW_1', 'DOW_2', 'DOW_3', 'DOW_4', 'DOW_5', 'DOW_6']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the total orders by the hour of the day and assigning it to a column\n",
    "food_df['Total orders_HR'] = food_df[[f'HR_{i}' for i in range(24)]].sum(axis=1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.head() #Getting the first rows to check the if the new feautres are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['Total orders'].unique() # Getting the unique values of total_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['Total orders_HR'].unique() # Getting the unique values of total_orders_HR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This difference betweeen the total order and the total order by hour might give us an insight on the HR_O column, which has missing values(as observed in the mssing values section). Since this difference only occurs when there are nan in the HR_0 column, we will use this to fill in the missing values of the HR_0 Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creting a discrepancy variable to check the difference between Total order and Total_orders_HR \n",
    "discrepancy = food_df['Total orders']- food_df['Total orders_HR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrepancy.unique() #Chekcing the unique values just for observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assure that there is a difference in the total orders by DOW and HR, thus, the values of the discrepancy, will be used to fill in the missing values in the `HR_0 column`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting an overral statistics of our dataset columns\n",
    "num_food_df.describe().round() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CUI beverages is empty\n",
    "* CUI Cafe is also empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `customer_age`: The standard deviation of 7 indicates that the ages are around the mean, with most ages likely within 21 to 35 (within one standard deviation of the mean). However, the maximum age of 80 shows there's a significant age outlier or a small group of much older customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `CUI_`: as we can see, the Cuisines columns have outliers. For example, for the CUI_Asian, the mean is 10 and the std is 24 and the max value is 897.  Since all values below the 75th percentile are zero, this means that at least 75% of the data is clustered at zero. The remaining 25% includes all non-zero values, likely including the extreme outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe possible outliers in the other columns too. Thus, we will deepen this analysis through visualization tools. But let as try and check the percentage of outliers for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating the Percentage of outliers per each column**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inter-Quartile Range formula:\n",
    "\n",
    "<br>\n",
    "\n",
    "$IQR = Q_3 – Q_1$\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "**Outliers** are the observations that fall\n",
    "- below $Q_1 − 1.5 \\times IQR$\n",
    "\n",
    "or\n",
    "\n",
    "- above $Q_3 + 1.5 \\times IQR$\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_percentages = {}\n",
    "\n",
    "# We know that low outliers are below Q 1 − 1.5 ⋅ IQR ‍ and high outliers are above Q 3 + 1.5 ⋅ IQR \n",
    "for column in food_df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(food_df[column]):\n",
    "        #Defining Q1 and Q3 to then find IQR \n",
    "        Q1 = food_df[column].quantile(0.25)\n",
    "        Q3 = food_df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        #Getting the outliers below the first quantile and above the second quantile\n",
    "        outliers = food_df[(food_df[column] < (Q1 - 1.5 * IQR)) | (food_df[column] > (Q3 + 1.5 * IQR))]\n",
    "        #Getting the percentage of the outliers\n",
    "        percentage_outliers = (len(outliers) / len(food_df)) * 100\n",
    "        outlier_percentages[column] = percentage_outliers\n",
    "\n",
    "#Printing the results and counting the number of columns per the percentage higher or lower than 5.\n",
    "nr_col_lower_5=0\n",
    "nr_col_higher_5=0\n",
    "print(\"Percentage of outliers per column using IQR:\")\n",
    "for column, percentage in outlier_percentages.items():\n",
    "    print(f\"{column}: \\033[1;35m{percentage:.2f}%\\033[0m\")\n",
    "    if percentage <5:\n",
    "        nr_col_lower_5+=1\n",
    "    if percentage >5:\n",
    "        nr_col_higher_5+=1\n",
    "\n",
    "#Printing the number of columns who have a percentage lower than 5% and then higher than 5%. \n",
    "# We chose 5% becasue it was the percentage advised during classes\n",
    "print(f\"From the columns, \\033[1;33m{nr_col_lower_5}\\033[0m have a percentage lower than 5%\")\n",
    "print(f\"From the columns, \\033[1;33m{nr_col_higher_5}\\033[0m have a percentage higher than 5%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed, there are plenty of columns with outliers, but before removing them, we have to firsstly analyse if it makes sense to remove them or not. For example, the `CUI columns` which have highest percentages of outliers, we should analise first what it means and how they affect our objective.  The quantile function skips missing values by default, however, they do reduce the number of data points, which could slightly affect the precision of the outlier threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Key Takeaways-Trends and anomalies`:\n",
    "* We have found the values of the HR_0 column, whihc we initially thought as beeing empty beacsue no one buys at that time.\n",
    "\n",
    "* We have observed that there a considerate ammount of ouliers in our dataset, and how they behave in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning the categorical features into a varibale called cat_food_df\n",
    "cat_food_df=food_df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_food_df.describe() #Getting the statistics of the cateorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Through Academic knowledge, we know that there 4 types of customer segmentation:**\n",
    "* Demographic Segmentation\n",
    "* Geographic Segmentation\n",
    "* Psychographic Segmentation\n",
    "* Behavioral Segmentation\n",
    "\n",
    "**Hence, for we will take a closer look into our Region feature which is a geographic feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.customer_region.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 customer regions in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the frequency of orders per each region\n",
    "food_df.customer_region.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see that as a percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the perceante of entries for each custmer region\n",
    "percentage_region=food_df.customer_region.value_counts(normalize=True) *100\n",
    "percentage_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the following regions have a percentage of entries higher than 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the regions with the entries higher than 10%\n",
    "for region, percent in percentage_region[percentage_region > 10].items():\n",
    "    print(f\"Region \\033[1;35m{region}\\033[0m: {percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be interesting to know why these are the regions with the most entries, and why are the other 5 regions with such low percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, these insights about the regions might help us if we decide to do geographic segmentation. Let us analyse the column with other categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a cross-tabulation to see the percentage of times each combination of customer region and last promo appears in the dataset\n",
    "pd.crosstab(food_df['customer_region'], food_df['last_promo'], normalize=True) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we had replaced \"-\" by nan, but when we did the analysis here, we realized it would be important to not only see where we have data, but also where we don´t, as it might give as an insight on our customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from this crosstab, the regions with the highest entries, are also the `customer regions` with the highest \"empty\" entries in the `last_promo` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a cross-tabulation to see the percentage of times each combination of last promo and payment method appears in the dataset\n",
    "pd.crosstab(cat_food_df['last_promo'], cat_food_df['payment_method'], normalize=True) *100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the percentage of each type of promotion\n",
    "cat_food_df['last_promo'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, the \"empty\" entries in the `last_promo` column have the highest entries in each type of `payment_method`, which can possibly mean that most of the orders are done when there is no promotion, assuming \"empty\" means no promotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a cross-tabulation to see the percentage of times each combination of customer region and payment method appears in the dataset\n",
    "pd.crosstab(cat_food_df['customer_region'], cat_food_df['payment_method'], normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CARD payment_methd seems to be the dominating one in every region, followed by DIGITAL and then CASH. This gives us an insight on our customers behaviours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Key Takeaways-Customer Behaviour`:\n",
    "* The highest payment method in all the regions is by CARD\n",
    "\n",
    "* When people make orders with a promotion, the one with highest entries is the delivery promotion, but more than half of the orders are done with no promotions\n",
    "\n",
    "* From the customer regions, 3 of the regions represent more than 50% of the customer region entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3.Visual Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, we wil perform a visual analhysis of our features, starting by the univariate analysis and then proceed to Bivariate analysis, to egt better insights of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.1 Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falta adicionar as interpretações, to aborrecida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`customer_age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing  the distribution of customer age in our dataset, using an histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(food_df['customer_age'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Customer Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.show()\n",
    "\n",
    "#intrepertar com: normal distribution, range, concentração, e skewness, outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot this column in a boxplot to better see the outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the distribution of customer age with a boxplot to better visualize the outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(food_df['customer_age'].dropna(), vert=False, patch_artist=True, boxprops=dict(facecolor=\"skyblue\"))\n",
    "plt.title('Customer Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Total Orders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Total orders per customer in an histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(food_df['Total orders'], bins=100, color='lightgreen', edgecolor='black')\n",
    "plt.title('Distribution of Total Orders per Customer')\n",
    "plt.xlabel('Total Orders')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly skewed distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Vendor Count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing  the distribution of Vendor count in our dataset, using an histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(food_df['vendor_count'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Vendor Count distribution')\n",
    "plt.xlabel('Vendor Count')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the distribution of Vendor Count with a boxplot to better visualize the outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(food_df['vendor_count'].dropna(), vert=False, patch_artist=True, boxprops=dict(facecolor=\"skyblue\"))\n",
    "plt.title('Vender count Distribution')\n",
    "plt.xlabel('Vendor count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Is_Chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing  the distribution of is_chain in our dataset, using an histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(food_df['is_chain'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Is Chain distribution')\n",
    "plt.xlabel('Is Chain')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the distribution of Vendor Count with a boxplot to better visualize the outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(food_df['is_chain'].dropna(), vert=False, patch_artist=True, boxprops=dict(facecolor=\"skyblue\"))\n",
    "plt.title('is chain Distribution')\n",
    "plt.xlabel('is chain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Key Takeaways`- Univariate Analysis:\n",
    "* Features with very skewed distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Total orders by hour of the day`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_of_the_day = [f'HR_{i}' for i in range(24)]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(hours_of_the_day, food_df[hours_of_the_day].sum(), marker='o', color='b')\n",
    "plt.title('Total Orders by Hour of the Day')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Total Orders')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Time of the day`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating \n",
    "time_of_day_columns = ['midday_orders', 'evening_orders', 'late_night_orders']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "food_df[time_of_day_columns].sum().plot(kind='bar', color=['#66c2a5', '#fc8d62', '#8da0cb'])\n",
    "plt.title('Order Distribution by Time of Day')\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Total Orders')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cuisines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_columns = [col for col in food_df.columns if col.startswith('CUI_')]\n",
    "cuisine_totals = food_df[cuisine_columns].sum().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "cuisine_totals.plot(kind='bar', color='orange', edgecolor='black')\n",
    "plt.title('Cuisine Popularity Based on Total Orders')\n",
    "plt.xlabel('Cuisine Type')\n",
    "plt.ylabel('Total Orders')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Vendor count and Product count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(food_df['vendor_count'], food_df['product_count'], color='purple')\n",
    "plt.title('Vendor Count vs. Product Count')\n",
    "plt.xlabel('Vendor Count')\n",
    "plt.ylabel('Product Count')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`First order and Last order`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a DataFrame for boxplot\n",
    "order_data = pd.DataFrame({\n",
    "    'First Order': food_df['first_order'],\n",
    "    'Last Order': food_df['last_order']\n",
    "})\n",
    "\n",
    "# Melt the DataFrame for seaborn\n",
    "order_data_melted = order_data.melt(var_name='Order Type', value_name='Days Since Creation')\n",
    "\n",
    "# Plot the boxplot\n",
    "sns.boxplot(x='Order Type', y='Days Since Creation', data=order_data_melted)\n",
    "plt.title('Distribution of Days Since First and Last Orders')\n",
    "plt.xlabel('Order Type')\n",
    "plt.ylabel('Days Since Creation')\n",
    "plt.show()\n",
    "\n",
    "#TODO procurar uma solução  melhor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Correlation Matrix between orders, vendor_count, product_count, is_chain, first and last order`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'midday_orders', 'evening_orders', 'late_night_orders',\n",
    "    'Total orders', 'vendor_count', 'product_count', \n",
    "    'customer_age', 'is_chain','first_order', 'last_order'\n",
    "]\n",
    "\n",
    "# Step 2: Calculate the correlation matrix for the selected features\n",
    "correlation_matrix = food_df[selected_features].corr()\n",
    "\n",
    "# Step 3: Create the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True,  # Show correlation coefficients\n",
    "            fmt='.2f',   # Format for the annotation\n",
    "            cmap='coolwarm',  # Color map\n",
    "            square=True,  # Make cells square\n",
    "            cbar_kws={\"shrink\": .8},  # Color bar size\n",
    "            linewidths=0.5,  # Lines between cells\n",
    "            vmin=-1,  # Minimum limit for color bar\n",
    "            vmax=1)  # Maximum limit for color bar\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Correlation Heatmap of Selected Features')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x labels for readability\n",
    "plt.yticks(rotation=0)  # Keep y labels horizontal\n",
    "plt.tight_layout()  # Adjust layout to fit labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Key Takeaways`-Bivariate Analysis:\n",
    "* Something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.2 Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Customer Region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO mudar o grafico\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Calculate percentage for each payment method\n",
    "payment_method_percentage = cat_food_df['customer_region'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Plot the percentages\n",
    "payment_method_percentage.plot(kind='bar', color=['#66b3ff'])\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of Customer Region (Percentage)')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Percentage (%)')\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Payment Methods`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO mudar o grafico\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Calculate percentage for each payment method\n",
    "payment_method_percentage = food_df['payment_method'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Plot the percentages\n",
    "payment_method_percentage.plot(kind='bar', color=['#66b3ff'])\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of Payment Methods (Percentage)')\n",
    "plt.xlabel('Payment Method')\n",
    "plt.ylabel('Percentage (%)')\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Last Promotion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO mudar o grafico\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Calculate percentage for each payment method\n",
    "payment_method_percentage = cat_food_df['last_promo'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Plot the percentages\n",
    "payment_method_percentage.plot(kind='bar', color=['#66b3ff'])\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of Last Promo (Percentage)')\n",
    "plt.xlabel('Last Promotion')\n",
    "plt.ylabel('Percentage (%)')\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Key Takeaways`-Univariate Analysis:\n",
    "* Something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Promo vs. Payment Method\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=food_df, x='payment_method', hue='last_promo')\n",
    "plt.title('Last Promo vs. Payment Method')\n",
    "plt.xlabel('Payment Method')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Last Promo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=food_df, x='payment_method', hue='customer_region')\n",
    "plt.title('Last Promo vs. Region')\n",
    "plt.xlabel('Payment Method')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=food_df, x='last_promo', hue='customer_region')\n",
    "plt.title('Last Promo vs. customer region')\n",
    "plt.xlabel('Payment Method')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Key Takeaways`-Bivariate Analysis:\n",
    "* Something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#food_df['HR_0'] = food_df['HR_0'].fillna(food_df['Total orders'] - food_df['Total orders_HR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trocar os NaN por No Promotion\n",
    "#food_df['last_promo'] = food_df['last_promo'].fillna('NOPROMO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['DOW_0', 'DOW_1', 'DOW_2', 'DOW_3', 'DOW_4', 'DOW_5', 'DOW_6', \n",
    "                   'HR_0', 'HR_1', 'HR_2', 'HR_3', 'HR_4', 'HR_5', 'HR_6', 'HR_7', \n",
    "                   'HR_8', 'HR_9', 'HR_10', 'HR_11', 'HR_12', 'HR_13', 'HR_14', \n",
    "                   'HR_15', 'HR_16', 'HR_17', 'HR_18', 'HR_19', 'HR_20', 'HR_21', \n",
    "                   'HR_22', 'HR_23', 'Total orders_HR', \n",
    "                   'CUI_American', 'CUI_Asian', 'CUI_Beverages', 'CUI_Cafe', \n",
    "                   'CUI_Chicken Dishes', 'CUI_Chinese', 'CUI_Desserts', \n",
    "                   'CUI_Indian', 'CUI_Italian', 'CUI_Japanese', 'CUI_Noodle Dishes', \n",
    "                   'CUI_Thai']\n",
    "\n",
    "# Drop the columns from the DataFrame\n",
    "food_df = food_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new order of columns\n",
    "new_column_order = ['customer_region', 'customer_age', \n",
    "                    'vendor_count', 'product_count', 'is_chain', \n",
    "                    'first_order', 'last_order', 'last_promo', \n",
    "                    'midday_orders', 'evening_orders', 'late_night_orders', \n",
    "                    'payment_method', \n",
    "                    'Western_Cuisine', 'Asian_Cuisine', 'Desserts_Beverages', \n",
    "                    'CUI_Healthy', 'CUI_OTHER', 'CUI_Street Food / Snacks', \n",
    "                    'Total orders', 'Weekday', 'Weekend']\n",
    "\n",
    "# Reorder the columns\n",
    "food_df = food_df[new_column_order]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
